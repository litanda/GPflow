{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib #\n",
    "from gpflow.utilities import print_summary\n",
    "import pandas as pd\n",
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "import warnings\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import os, sys\n",
    "import csv\n",
    "\n",
    "\n",
    "# The lines below are specific to the notebook format\n",
    "%matplotlib inline\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (12, 10),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "matplotlib.rcParams.update(params)\n",
    "plt = matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The global_kernel class is to find GP kernels which are suitable for global stellar parameters (e.g. Teff, Radius) \n",
    "#and resample them as a function of the age. \n",
    "class global_2d_kernel:\n",
    "    '''\n",
    "    The global_kernel class aims to find an proper and efficient GP kernel for a global parameter (e. g. Teff) for\n",
    "    the whole grid.  \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, datapath = None, savepath = None):\n",
    "        return None\n",
    "    \n",
    "    def set_path(self, datapath = None, savepath = None):\n",
    "        self._datapath = datapath\n",
    "        self._savepath = savepath\n",
    "        \n",
    "        if not os.path.exists(datapath):\n",
    "            raise Warning(f'datapath:' + datapath + ' does not exist')\n",
    "        \n",
    "        if not os.path.exists(savepath): os.makedirs(savepath)\n",
    "        \n",
    "        print('Data path is set as' + self._datapath)\n",
    "        print('Save path is set as' + self._savepath)\n",
    "        return self\n",
    "    \n",
    "    #############################################################################################################\n",
    "    ################Change this function for different data formats##############################################\n",
    "    #############################################################################################################\n",
    "    def get_data_of_a_grid(self, condition = None, \n",
    "                           x = None, y = None,\n",
    "                           xrange = None, yrange = None,\n",
    "                           xlog = None, ylog = None, \n",
    "                           validation_frac = None):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_data_of_a_track(self, filename = None, p = None, \n",
    "                            fraction = None, random_state = None):\n",
    "        '''\n",
    "        To split a track into two subssets for training and testing with a given fraction. \n",
    "        The training set has an maxmum number of 1000. \n",
    "        outputs:\n",
    "        training set: gpx, gpy,\n",
    "        testing set: gpx_v, gpy_v\n",
    "        '''\n",
    "        one_track = []\n",
    "        one_track = pd.read_csv(filename)\n",
    "        #get rid of the pre-MS\n",
    "        one_track = one_track.loc[one_track['center_h1'] <= 0.997*np.max(one_track['center_h1']) ]\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def abc(self):\n",
    "        one_track = one_track[[x1,x2,y]]\n",
    "        if (x1log == True): one_track[x1] = np.log10(one_track[x1])\n",
    "        if (x2log == True): one_track[x2] = np.log10(one_track[x2])        \n",
    "        if (ylog == True): one_track[y] = np.log10(one_track[y])\n",
    "        one_track = one_track.replace([np.inf, -np.inf], np.nan)\n",
    "        one_track.isna().sum()\n",
    "        one_track = one_track.dropna()\n",
    "        \n",
    "        yrange = [np.min(one_track[y]), np.max(one_track[y])]\n",
    "        x1range = [np.min(one_track[x1]), np.max(one_track[x1])]\n",
    "        x2range = [np.min(one_track[x2]), np.max(one_track[x2])]\n",
    "        \n",
    "        if (ynormalization == True): \n",
    "            one_track[y] = (one_track[y] - min(yrange))/(max(yrange) - min(yrange))\n",
    "        \n",
    "        if (x1normalization == True): \n",
    "            one_track[x1] = (one_track[x1] - min(x1range))/(max(x1range) - min(x1range)) \n",
    "        if (xnormalization == True): \n",
    "            one_track[x2] = (one_track[x2] - min(x2range))/(max(x2range) - min(x2range)) \n",
    "        \n",
    "        if (random_state == None): random_state = 0\n",
    "        \n",
    "        if (len(one_track[y])*fraction >= 1000):\n",
    "            train = one_track.sample( n = 1000, random_state=random_state) #random state is a seed value\n",
    "        else:\n",
    "            train = one_track.sample(frac = fraction, random_state=random_state) #random state is a seed value\n",
    "        train = train.sort_index()\n",
    "        test = one_track.drop(train.index)\n",
    "        test = test.sort_index()\n",
    "        \n",
    "        gpy = train[y].to_numpy().reshape(-1, 1)\n",
    "        gpy = np.float64(gpy)\n",
    "        gpx1 = train[x1].to_numpy().reshape(-1, 1)        \n",
    "        gpx1 = np.float64(gpx1)\n",
    "        gpx2 = train[x1].to_numpy().reshape(-1, 1)        \n",
    "        gpx2 = np.float64(gpx2)\n",
    "        \n",
    "        gpy_v = test[y].to_numpy().reshape(-1, 1)\n",
    "        gpy_v = np.float64(gpy_v)        \n",
    "        gpx1_v = test[x1].to_numpy().reshape(-1, 1)\n",
    "        gpx1_v = np.float64(gpx1_v)\n",
    "        gpx2_v = test[x2].to_numpy().reshape(-1, 1)\n",
    "        gpx2_v = np.float64(gpx2_v)\n",
    "        return gpx1, gpx2, gpy, gpx1_v, gpx2_v, gpy_v, x1range, x2range, yrange\n",
    "    #############################################################################################################\n",
    "    \n",
    "    def preview_2d_data(self, condition = None, number = None,\n",
    "                        x1 = None, x2 = None ,y = None, \n",
    "                        x1log = None, x2log = None, ylog = None, \n",
    "                        x1normalization = None, x2normalization = None, ynormalization = None,\n",
    "                        savefig = None):\n",
    "        \n",
    "        if condition == None:\n",
    "            warnings.warn(f'$condition$ is missing, all csv files in datapath will be used', UserWarning)\n",
    "            condition = \"*.csv\"\n",
    "        if number == None:\n",
    "            warnings.warn(f'$number$ is missing, 5 file will be used', UserWarning)\n",
    "            number = 5\n",
    "            \n",
    "        if (x == None) or (y == None) or (type(x) != str) or (type(y) != str): \n",
    "            raise Warning(f'$X$ and $Y$ must be given with the type of string')\n",
    "    \n",
    "        all_files = glob.glob(self._datapath + condition)\n",
    "        random.shuffle(all_files)\n",
    "        n = min([int(number), len(all_files)])\n",
    "        files= all_files[0:n]\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.xlabel(x)\n",
    "        plt.ylabel(x2)\n",
    "        plt.title('Preview of ' + x + ' vs ' + x2 + ' color: ' + y)\n",
    "        for filename in files:\n",
    "            print(filename)\n",
    "            gpx1, gpx2, gpy, gpx1_v, gpx2_v gpy_v, x1range, x2range, yrange = \\\n",
    "            self.get_data_of_a_track(filename, x1, x2, y, x1log, x2log, ylog, \\\n",
    "                                     x1normalization, x2normalization, \n",
    "                                     ynormalization, fraction = 0.9)\n",
    "            plt.scatter(gpx1, gpx2, c = gpy)\n",
    "        if (savefig == True): plt.savefig(self._savepath + 'S00_' + x1 + '_vs_' + x2 '_vs_' + y + 'preview.png')\n",
    "        return None\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global_kernel \n",
    "\n",
    "The global_kernel class is to find proper GP kernels for global stellar parameters (e.g. Teff, Radius) and resample them as a function of the age. \n",
    "\n",
    "A recomended step-by-step procudure for a stellar parameter is: \n",
    "1. 'global_kernel.preview_1d_data'ï¼špreview data with to see which kernels could be used;  \n",
    "2. 'global_kernel.generate_kernel_grid' or manually: set up a list of kernels \n",
    "3. 'global_kernel.find_1d_kernel': find the best kernel for a certain parameter with a random selected subset in the grid\n",
    "4. 'global_kernel.gpmodel': use the kernel found in step 3 and obtain one gp model for each global parameter on each track (as a function of stellar age) \n",
    "5. 'global_kernel.resample': resample each evolutaionary track  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1 preview data\n",
    "The purpose of vasual inspection is find out which kernals may work for the parameter. The effective temperature is the most tricky parameter. Because the curve changes sharply with age at the beginning and the ending parts (pre-MS and giant phases) and is spiky at the turn-off points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadr = '/Users/litz/Documents/GitHub/data/simple_grid_mixed_modes_subset1/'\n",
    "savedr = '/Users/litz/Documents/GitHub/GPflow/2d-teff/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = global_2d_kernel()\n",
    "g2.set_path(datapath = datadr, savepath = savedr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1 preview data\n",
    "The purpose of vasual inspection is find out which kernals may work for the parameter.\n",
    "The effective temperature is the most tricky parameter. Because the curve changes sharply with age at the beginning and the ending parts (pre-MS and giant phases) and is spiky at the turn-off points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gk.preview_1d_data(condition = '*.csv', number = 8,\n",
    "                   x = 'star_age', y = 'effective_T', \n",
    "                   x2 = False, xlog = False, ylog = False, \n",
    "                   xnormalization = True, ynormalization = True,\n",
    "                   savefig = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 make initial guess of the kernel\n",
    "\n",
    "individual kernel names are: ['constant','linear','poly2','poly3', 'poly4', 'poly5', 'poly6','cosine','arccosine', 'exponential', 'periodic', 'se', 'rq', 'matern12', 'matern32', 'matern52','static','white']\n",
    "\n",
    "kernel combinations are also available. Three notes: 1) kernel names and math symbols MUST be seperated by spaces, e.g. 'constant + linear * poly2'; 2) combinations with + - * / are surpported; 3) do not use parentheses or brackets. For the case like '(se + poly3) * linear', please use 'se * linear + ploy3 * linear'\n",
    "\n",
    "Examples:\n",
    "\n",
    "kernels =  ['poly3', 'poly4', 'se', 'rq', 'matern12', 'matern32', 'matern52']\n",
    "\n",
    "kernel_combinations = ['constant + se', 'se + matern12', 'constant + poly3 + se', 'constant + poly3 + rq', 'linear * linear + se'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadr = '/Users/litz/Documents/GitHub/data/simple_grid_mixed_modes_subset1/'\n",
    "savedr = '/Users/litz/Documents/GitHub/GPflow/2D-teff/test1/'\n",
    "\n",
    "gk = global_kernel()\n",
    "gk.set_path(datapath = datadr, savepath = savedr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['se', 'rq', 'exponential', 'matern12']\n",
    "kernel_combinations = [\n",
    "                       'constant + exponential',\n",
    "                       'constant + matern12',\n",
    "                       'se + matern12',\n",
    "                       'rq + matern12',\n",
    "                       'se + exponential',\n",
    "                       'rq + exponential',\n",
    "                       'matern12 + matern32',\n",
    "                       'matern12 + exponential',\n",
    "                       'matern12 + matern12',\n",
    "                       'exponential + exponential'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also check kernel functions with following codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotkernelfunction(k = None, ax = None, xmin=None, xmax=None, other=None, kname = None):\n",
    "    xx = np.linspace(xmin, xmax, 200)[:,None]\n",
    "    ax.plot(xx, k(xx, np.zeros((1,1)) + other))\n",
    "    ax.set_title(kname)\n",
    "\n",
    "for kname in kernels:\n",
    "    kernel = gk.kernel_bank(kname)\n",
    "    f, axes = plt.subplots(1, 1, figsize=(6, 5), sharex=True)\n",
    "    plotkernelfunction(k = kernel, ax = axes, xmin=-3, xmax=3, other=1.0, kname = kname)\n",
    "    \n",
    "for kname in kernel_combinations:\n",
    "    kernel = gk.solve_kernel_combinations(kname)\n",
    "    f, axes = plt.subplots(1, 1, figsize=(6, 5), sharex=True)\n",
    "    plotkernelfunction(k = kernel, ax = axes, xmin=-3, xmax=3, other=1.0, kname = kname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 use a subset to test kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "teff_offset = gk.find_1d_kernel(condition = '*.csv',\n",
    "                                subset_fraction = 0.2, \n",
    "                                x = 'star_age', y = 'effective_T', \n",
    "                                x2 = False, xlog = False, ylog = False,\n",
    "                                xnormalization = True,\n",
    "                                ynormalization = True,\n",
    "                                kernels = kernels, \n",
    "                                kernel_combinations = kernel_combinations,\n",
    "                                iterations = 10, validation_frac = 0.4,\n",
    "                                printinfo = False, figures = True)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teff_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teff_offset.to_csv(savedr + 'teff_kernel_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got several kernels which look promising. They are\n",
    "\n",
    "exponential, matern12, constant + exponetial, constant + matern12, matern12 + matern12, exponential + exponential, matern12 + exponential\n",
    "\n",
    "We may want a second match with only those kernels but more files and see who wins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datadr = '/Users/litz/Documents/GitHub/data/simple_grid_mixed_modes_subset1/'\n",
    "savedr = '/Users/litz/Documents/GitHub/GPflow/teff/test2/'\n",
    "\n",
    "gk = global_kernel()\n",
    "gk.set_path(datapath = datadr, savepath = savedr)\n",
    "\n",
    "\n",
    "kernels = ['exponential' ,'matern12']\n",
    "kernel_combinations = [\n",
    "                       'constant + exponential',\n",
    "                       'constant + matern12',\n",
    "                       'matern12 + exponential',\n",
    "                       'matern12 + matern12',\n",
    "                       'exponential + exponential'\n",
    "                      ]\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "teff_offset_2 = gk.find_1d_kernel(condition = '*.csv',\n",
    "                                subset_fraction = 0.3, \n",
    "                                x = 'star_age', y = 'effective_T', \n",
    "                                x2 = False, xlog = False, ylog = False,\n",
    "                                xnormalization = True,\n",
    "                                ynormalization = True,\n",
    "                                kernels = kernels, \n",
    "                                kernel_combinations = kernel_combinations,\n",
    "                                iterations = 10, validation_frac = 0.5,\n",
    "                                printinfo = False, figures = True)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teff_offset_2.to_csv(savedr + 'teff_kernel_test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teff_offset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(teff_offset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(teff_offset_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Apply the best GP kernel to the whole grid\n",
    "\n",
    "We found that 'matern12' is the best and the most stable kernel. We hence apply it to the whole grid. \n",
    "\n",
    "gk.apply_1d_kernel uses an input kernel to model a stellar parameter as a function of the other parameter for each evolutionary track. The output is one GP model per track. \n",
    "\n",
    "gk.apply_1d_kernel returns a pandas.dataframe which content the deviation between the GP model and the data for each evolutionary track. The dataframe looks like: \n",
    "\n",
    "-------------\n",
    "index,     evolutionary_track,       x,          y,        xlog,    ylog,     xrange,       yrange,         xnormalization,     ynormalization,     mean_deviation,     max_deviation,        saveGPmodel         \n",
    "\n",
    "  1,      m1.0_feh2.0_MLT...,   star_age,   effective_T,    True,    True,  [-4.5, 10.],   [3.6,3.8] ,       Ture ,     Ture,      1.0d-8,            1.0d-4,     GPmodel-effective_T...\n",
    "  ......\n",
    "\n",
    "validate_mean and validate_sigma is the mean and the standard devitation of the probability distribution of residuals between model and data. The two parameters will be used to estimate the uncertainty of a predication value. \n",
    "\n",
    "xrange and yrange gives a parameter space in which the derived GP model can be trust. Obviously, this space can not exceed the min/max of x and y values. To avoid edge effects, we removed edge spaces where model predictions is 3sigma away from validations.      \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadr = '/Users/litz/Documents/GitHub/data/simple_grid_mixed_modes_subset1/'\n",
    "savedr = '/Users/litz/Documents/GitHub/GPflow/teff/'\n",
    "gk = global_kernel()\n",
    "gk.set_path(datapath = datadr, savepath = savedr)\n",
    "\n",
    "\n",
    "kernels = ['exponential + exponential']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "gk_outputs = gk.apply_1d_kernel(condition = '*.csv',\n",
    "                                      x = 'star_age', y = 'effective_T', x2 = False, \n",
    "                                      xlog = False, ylog = False,\n",
    "                                      xnormalization = True, ynormalization = True,\n",
    "                                      validation_frac = 0.4,\n",
    "                                      kernels = kernels, \n",
    "                                      combination = True,\n",
    "                                      iterations = 10,\n",
    "                                      savemodelprefix = 'GPmodel-effective_T-',\n",
    "                                      printinfo = False, \n",
    "                                      figures = True,\n",
    "                                      savetablename = 'gk_outputs.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gk_outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#offsets = 10**(3.7 + gk_outputs['mean_deviation']) - 10**3.700000\n",
    "\n",
    "offsets = gk_outputs['mean_deviation']\n",
    "print(np.mean(offsets), \n",
    "      np.min(offsets), \n",
    "      np.max(offsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#offsets = 10**(3.7 + gk_outputs['max_deviation']) - 10**3.700000\n",
    "\n",
    "offsets = gk_outputs['max_deviation']\n",
    "\n",
    "print(np.mean(offsets), \n",
    "      np.min(offsets), \n",
    "      np.max(offsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Use models to predict/interpolate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadr = '/Users/litz/Documents/GitHub/data/simple_grid_mixed_modes_subset1/'\n",
    "savedr = '/Users/litz/Documents/GitHub/GPflow/teff/'\n",
    "gk = global_kernel()\n",
    "gk.set_path(datapath = datadr, savepath = savedr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gptablename = savedr + 'GPmodel-effective_T-gk_outputs.csv'\n",
    "gpdictpath = savedr + 'GPmodel-effective_T-dicts/'\n",
    "gpdatapath = savedr + 'GPmodel-effective_T-dicts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {'saveGPmodel': object} #, 'saveGPmodel': str, 'saveGPdata': str}\n",
    "\n",
    "gptable = gk.load_gp_bank(tablename = gptablename, dtype=dtype, gpdictpath = gpdictpath, gpdatapath = gpdatapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackname = 'm1.53_feh3.0_MLT1.9_fov0.018'\n",
    "tablerow = gptable.loc[gptable['evolutionary_track'] == trackname] \n",
    "tablerow.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(tablerow['xrange'].all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x_input need to have same unit with the data grid!\n",
    "# parameter    unit\n",
    "#   age       year\n",
    "#  Teff        K\n",
    "#  logg       dex\n",
    "#  radius     solar\n",
    "#luminosity   solar\n",
    "#frequency    microHz\n",
    "\n",
    "x_input = np.linspace(2e9, 3e9, num=100)\n",
    "\n",
    "track_x, track_y, \\\n",
    "track_x_v, \\\n",
    "track_y_v, track_y_v_e, \\\n",
    "x_new, \\\n",
    "y_new, y_new_e = gk.use_gp_model(model_dict = tablerow['saveGPmodel'].all(), \n",
    "                                  model_data = tablerow['saveGPdata'].all(), \n",
    "                                  x = tablerow['x'].all(), y = tablerow['y'].all(), \n",
    "                                      x2 = tablerow['x2'].all(), \n",
    "                                      xlog = tablerow['xlog'].all(), ylog = tablerow['ylog'].all(),\n",
    "                                      xrange = eval(tablerow['xrange'].all()), \n",
    "                                      yrange = eval(tablerow['yrange'].all()),\n",
    "                                      xnormalization = tablerow['xnormalization'].all(), \n",
    "                                      ynormalization = tablerow['ynormalization'].all(),\n",
    "                                      kernels = [tablerow['kname'].all()], \n",
    "                                      combination = tablerow['combination'].all(),\n",
    "                                      x_input = x_input)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(track_x/1.0e9, track_y, 'k')\n",
    "plt.errorbar(x_new/1.0e9, y_new, yerr = y_new_e, c = 'r', marker = '.')\n",
    "plt.xlabel('Age (Gyr)')\n",
    "plt.ylabel(r'Teff (K)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(track_x_v/1.e9, track_y_v_e, 'b-')\n",
    "plt.plot(x_new/1.e9, y_new_e, 'k.')\n",
    "plt.xlabel('Age (Gyr)')\n",
    "plt.ylabel(r'err_Teff (K)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10000/(32/20)/60/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
